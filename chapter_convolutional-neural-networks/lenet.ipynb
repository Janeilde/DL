{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ceb44ec3",
      "metadata": {
        "id": "ceb44ec3"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==0.17.6 --no-deps\n",
        "!pip install numpy>=1.22\n"
      ],
      "metadata": {
        "id": "iQHYR2h6-7BC",
        "outputId": "5741e914-fdfe-4a7e-acf1-b6aa612c7554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iQHYR2h6-7BC",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==0.17.6\n",
            "  Downloading d2l-0.17.6-py3-none-any.whl.metadata (482 bytes)\n",
            "Downloading d2l-0.17.6-py3-none-any.whl (112 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/112.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/112.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: d2l\n",
            "Successfully installed d2l-0.17.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "id": "jdL6suLi_A4r",
        "outputId": "eae258ac-8b80-40fe-898f-4b680fc81be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jdL6suLi_A4r",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from d2l import torch as d2l\n",
        "import numpy as np\n",
        "print(\"✅ 安装成功，d2l 版本:\", d2l.__version__)\n",
        "print(\"✅ numpy 版本:\", np.__version__)\n"
      ],
      "metadata": {
        "id": "NqDzSnzx_vhc",
        "outputId": "1634f04f-aa7a-4d40-9098-4dec2363792c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "id": "NqDzSnzx_vhc",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'd2l.torch' has no attribute '__version__'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-2127600665.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ 安装成功，d2l 版本:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ numpy 版本:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'd2l.torch' has no attribute '__version__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import d2l\n",
        "import numpy as np\n",
        "\n",
        "print(\"✅ d2l 版本:\", d2l.__version__)\n",
        "print(\"✅ numpy 版本:\", np.__version__)\n"
      ],
      "metadata": {
        "id": "9W4yyIwb_009",
        "outputId": "699b4c4c-8fcc-4319-ad1d-f0eeaadc7034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9W4yyIwb_009",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ d2l 版本: 0.17.6\n",
            "✅ numpy 版本: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0a270651",
      "metadata": {
        "id": "0a270651",
        "outputId": "6fddf195-d87a-42dc-8d28-b9163abfad8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/d2l-ai/d2l-zh@release\n",
            "  Cloning https://github.com/d2l-ai/d2l-zh (to revision release) to /tmp/pip-req-build-nodx36u0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/d2l-ai/d2l-zh /tmp/pip-req-build-nodx36u0\n",
            "  Running command git checkout -b release --track origin/release\n",
            "  Switched to a new branch 'release'\n",
            "  Branch 'release' set up to track remote branch 'release' from 'origin'.\n",
            "  Resolved https://github.com/d2l-ai/d2l-zh to commit 843d3d41dca48d8df65f4b324dd171d8bfe9c067\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jupyter==1.0.0 (from d2l==2.0.0)\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "INFO: pip is looking at multiple versions of d2l to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.21.5 (from d2l) (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc1, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0rc1, 2.3.0, 2.3.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.21.5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "493c2d92",
      "metadata": {
        "origin_pos": 0,
        "id": "493c2d92"
      },
      "source": [
        "# 卷积神经网络（LeNet）\n",
        ":label:`sec_lenet`\n",
        "\n",
        "通过之前几节，我们学习了构建一个完整卷积神经网络的所需组件。\n",
        "回想一下，之前我们将softmax回归模型（ :numref:`sec_softmax_scratch`）和多层感知机模型（ :numref:`sec_mlp_scratch`）应用于Fashion-MNIST数据集中的服装图片。\n",
        "为了能够应用softmax回归和多层感知机，我们首先将每个大小为$28\\times28$的图像展平为一个784维的固定长度的一维向量，然后用全连接层对其进行处理。\n",
        "而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构。\n",
        "同时，用卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。\n",
        "\n",
        "本节将介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。\n",
        "这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 :cite:`LeCun.Bottou.Bengio.ea.1998`中的手写数字。\n",
        "当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。\n",
        "\n",
        "当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。\n",
        "LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。\n",
        "时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！\n",
        "\n",
        "## LeNet\n",
        "\n",
        "总体来看，(**LeNet（LeNet-5）由两个部分组成：**)(~~卷积编码器和全连接层密集块~~)\n",
        "\n",
        "* 卷积编码器：由两个卷积层组成;\n",
        "* 全连接层密集块：由三个全连接层组成。\n",
        "\n",
        "该架构如 :numref:`img_lenet`所示。\n",
        "\n",
        "![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](http://d2l.ai/_images/lenet.svg)\n",
        ":label:`img_lenet`\n",
        "\n",
        "每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用$5\\times 5$卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个$2\\times2$池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n",
        "\n",
        "为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务，所以输出层的10维对应于最后输出结果的数量。\n",
        "\n",
        "通过下面的LeNet代码，可以看出用深度学习框架实现此类模型非常简单。我们只需要实例化一个`Sequential`块并将需要的层连接在一起。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "589980bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:16:58.345112Z",
          "iopub.status.busy": "2023-08-18T07:16:58.344514Z",
          "iopub.status.idle": "2023-08-18T07:17:01.351069Z",
          "shell.execute_reply": "2023-08-18T07:17:01.349827Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "589980bb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
        "    nn.Linear(120, 84), nn.Sigmoid(),\n",
        "    nn.Linear(84, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b37131",
      "metadata": {
        "origin_pos": 5,
        "id": "b9b37131"
      },
      "source": [
        "我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的LeNet-5一致。\n",
        "\n",
        "下面，我们将一个大小为$28 \\times 28$的单通道（黑白）图像通过LeNet。通过在每一层打印输出的形状，我们可以[**检查模型**]，以确保其操作与我们期望的 :numref:`img_lenet_vert`一致。\n",
        "\n",
        "![LeNet 的简化版。](https://github.com/d2l-ai/d2l-zh-pytorch-colab/blob/master/img/lenet-vert.svg?raw=1)\n",
        ":label:`img_lenet_vert`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8d4dfb21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.355505Z",
          "iopub.status.busy": "2023-08-18T07:17:01.354784Z",
          "iopub.status.idle": "2023-08-18T07:17:01.371233Z",
          "shell.execute_reply": "2023-08-18T07:17:01.370166Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "8d4dfb21",
        "outputId": "ef2c6682-6645-43bb-a526-7afb99354244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
            "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
            "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
            "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
            "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
            "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
            "Flatten output shape: \t torch.Size([1, 400])\n",
            "Linear output shape: \t torch.Size([1, 120])\n",
            "Sigmoid output shape: \t torch.Size([1, 120])\n",
            "Linear output shape: \t torch.Size([1, 84])\n",
            "Sigmoid output shape: \t torch.Size([1, 84])\n",
            "Linear output shape: \t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81704149",
      "metadata": {
        "origin_pos": 10,
        "id": "81704149"
      },
      "source": [
        "请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。\n",
        "第一个卷积层使用2个像素的填充，来补偿$5 \\times 5$卷积核导致的特征减少。\n",
        "相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像素。\n",
        "随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后的16个。\n",
        "同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。\n",
        "\n",
        "## 模型训练\n",
        "\n",
        "现在我们已经实现了LeNet，让我们看看[**LeNet在Fashion-MNIST数据集上的表现**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d13d15dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.375937Z",
          "iopub.status.busy": "2023-08-18T07:17:01.374923Z",
          "iopub.status.idle": "2023-08-18T07:17:01.483390Z",
          "shell.execute_reply": "2023-08-18T07:17:01.481932Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "id": "d13d15dc",
        "outputId": "1c0f2f94-baf8-405d-85d5-7ede0e7350be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 115MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.81MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 58.5MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.5MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f18ba4f",
      "metadata": {
        "origin_pos": 12,
        "id": "2f18ba4f"
      },
      "source": [
        "虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。\n",
        "通过使用GPU，可以用它加快训练。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6cad2b",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "cf6cad2b"
      },
      "source": [
        "为了进行评估，我们需要[**对**] :numref:`sec_softmax_scratch`中描述的(**`evaluate_accuracy`函数进行轻微的修改**)。\n",
        "由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c868f5c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.489623Z",
          "iopub.status.busy": "2023-08-18T07:17:01.488809Z",
          "iopub.status.idle": "2023-08-18T07:17:01.498984Z",
          "shell.execute_reply": "2023-08-18T07:17:01.498112Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "c868f5c5"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
        "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()  # 设置为评估模式\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "    # 正确预测的数量，总预测的数量\n",
        "    metric = d2l.Accumulator(2)\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(X, list):\n",
        "                # BERT微调所需的（之后将介绍）\n",
        "                X = [x.to(device) for x in X]\n",
        "            else:\n",
        "                X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
        "    return metric[0] / metric[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2872a69",
      "metadata": {
        "origin_pos": 17,
        "id": "d2872a69"
      },
      "source": [
        "[**为了使用GPU，我们还需要一点小改动**]。\n",
        "与 :numref:`sec_softmax_scratch`中定义的`train_epoch_ch3`不同，在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如GPU）上。\n",
        "\n",
        "如下所示，训练函数`train_ch6`也类似于 :numref:`sec_softmax_scratch`中定义的`train_ch3`。\n",
        "由于我们将实现多层神经网络，因此我们将主要使用高级API。\n",
        "以下训练函数假定从高级API创建的模型作为输入，并进行相应的优化。\n",
        "我们使用在 :numref:`subsec_xavier`中介绍的Xavier随机初始化模型参数。\n",
        "与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8cb06c53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.504092Z",
          "iopub.status.busy": "2023-08-18T07:17:01.503194Z",
          "iopub.status.idle": "2023-08-18T07:17:01.520331Z",
          "shell.execute_reply": "2023-08-18T07:17:01.519209Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "8cb06c53"
      },
      "outputs": [],
      "source": [
        "#@save\n",
        "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
        "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "    net.apply(init_weights)\n",
        "    print('training on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    for epoch in range(num_epochs):\n",
        "        # 训练损失之和，训练准确率之和，样本数\n",
        "        metric = d2l.Accumulator(3)\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_l = metric[0] / metric[2]\n",
        "            train_acc = metric[1] / metric[2]\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,\n",
        "                             (train_l, train_acc, None))\n",
        "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
        "          f'test acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
        "          f'on {str(device)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d212797",
      "metadata": {
        "origin_pos": 22,
        "id": "1d212797"
      },
      "source": [
        "现在，我们[**训练和评估LeNet-5模型**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5d7b0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.525559Z",
          "iopub.status.busy": "2023-08-18T07:17:01.524508Z",
          "iopub.status.idle": "2023-08-18T07:17:54.484626Z",
          "shell.execute_reply": "2023-08-18T07:17:54.483337Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "4b5d7b0c",
        "outputId": "a12f08b9-4d61-43f9-bf6b-46f3ae3c2f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda:0\n"
          ]
        }
      ],
      "source": [
        "lr, num_epochs = 0.9, 10\n",
        "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4db919b",
      "metadata": {
        "origin_pos": 24,
        "id": "d4db919b"
      },
      "source": [
        "## 小结\n",
        "\n",
        "* 卷积神经网络（CNN）是一类使用卷积层的网络。\n",
        "* 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。\n",
        "* 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n",
        "* 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。\n",
        "* LeNet是最早发布的卷积神经网络之一。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 将平均汇聚层替换为最大汇聚层，会发生什么？\n",
        "1. 尝试构建一个基于LeNet的更复杂的网络，以提高其准确性。\n",
        "    1. 调整卷积窗口大小。\n",
        "    1. 调整输出通道的数量。\n",
        "    1. 调整激活函数（如ReLU）。\n",
        "    1. 调整卷积层的数量。\n",
        "    1. 调整全连接层的数量。\n",
        "    1. 调整学习率和其他训练细节（例如，初始化和轮数）。\n",
        "1. 在MNIST数据集上尝试以上改进的网络。\n",
        "1. 显示不同输入（例如毛衣和外套）时，LeNet第一层和第二层的激活值。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdd0db1",
      "metadata": {
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "cbdd0db1"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1860)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}